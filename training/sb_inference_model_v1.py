# -*- coding: utf-8 -*-
"""SB_Inference_Model_v0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nq5svk557v6HKT3zfIUXuAJibDZUfquc
"""

# === 1. Imports ===
import torch
import json
import os
import pickle

# === 2. Setup Directories ===
USER_TO_PLAYLISTS_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_playlist_match/user_to_neighboursPlaylists.pkl"
MODEL_WEIGHTS_PATH = "/content/drive/MyDrive/models/model.pth"
MODEL_CONFIG_PATH = "/content/drive/MyDrive/models/model_config.json"

# === 3. Load model config ===
with open(MODEL_CONFIG_PATH, "r") as f:
    model_config = json.load(f)

# === 4. Load full model ===
model = torch.load(MODEL_WEIGHTS_PATH, map_location="cpu", weights_only=False)
model.eval()

# === 5. Attach scoring function for inference ===
def score(user_ids, playlist_ids):
    u = model.user_embeddings(user_ids)
    p = model.playlist_embeddings(playlist_ids)
    return (u * p).sum(1)

model.score = score

# === 6. Load user-to-playlists mapping ===
with open(USER_TO_PLAYLISTS_PATH, "rb") as f:
    user_to_playlists = pickle.load(f)

# We will now find the 'mainstream user'. This is the user that is mapped to the most popular playlists. This user will replace 'cold users' when a cold user requests recommendations.
from collections import Counter

# Step 1: Count how many times each playlist appears
playlist_counter = Counter()
for playlists in user_to_playlists.values():
    playlist_counter.update(playlists)

# Step 2: Score each user by the *total popularity* of their playlists
user_scores = {
    user: sum(playlist_counter[p] for p in playlists)
    for user, playlists in user_to_playlists.items()
}

# Step 3: Find user with highest popularity score
mainstream_user_id = max(user_scores.items(), key=lambda x: x[1])[0]
print(f"Most mainstream user: {mainstream_user_id}")

# === 7. Ranking function (uses internal mapping) ===
def rank_playlists_for_user(user_id, top_k=10):
    playlists = user_to_playlists.get(user_id)

    if not playlists:
        print(f"User {user_id} has no matched playlists. Using mainstream user {mainstream_user_id} as fallback.")
        user_id = mainstream_user_id
        playlists = user_to_playlists.get(mainstream_user_id, [])

    if not playlists:
        return []

    user_tensor = torch.LongTensor([user_id] * len(playlists))
    playlist_tensor = torch.LongTensor(playlists)

    with torch.no_grad():
        scores = model.score(user_tensor, playlist_tensor)

    top_indices = torch.topk(scores, k=min(top_k, len(playlists))).indices
    return [playlists[i] for i in top_indices]


# === 8. Example usage ===
example_user = 99999999  # Try a cold user ID
top_playlists = rank_playlists_for_user(example_user, top_k=10)
print(f"Top playlists for user {example_user}:", top_playlists)

# Define mainstream user ID
mainstream_user_id = 841706

# Define batched inference function
def rank_playlists_for_users(user_ids: list[int], top_k=10):
    all_user_ids = []
    all_playlist_ids = []
    slice_bounds = []  # (user_id, start_idx, end_idx)

    for user_id in user_ids:
        playlists = user_to_playlists.get(user_id)

        if not playlists:
            # Fallback to mainstream user
            playlists = user_to_playlists.get(mainstream_user_id, [])
            effective_user_id = mainstream_user_id
        else:
            effective_user_id = user_id

        if playlists:
            start = len(all_user_ids)
            all_user_ids.extend([effective_user_id] * len(playlists))
            all_playlist_ids.extend(playlists)
            end = len(all_user_ids)
            slice_bounds.append((user_id, start, end))  # Keep original user_id for output
        else:
            slice_bounds.append((user_id, None, None))

    if not all_user_ids:
        return {user_id: [] for user_id in user_ids}

    user_tensor = torch.LongTensor(all_user_ids)
    playlist_tensor = torch.LongTensor(all_playlist_ids)

    with torch.no_grad():
        scores = model.score(user_tensor, playlist_tensor)

    result = {}
    for user_id, start, end in slice_bounds:
        if start is None:
            result[user_id] = []
        else:
            user_scores = scores[start:end]
            user_playlists = all_playlist_ids[start:end]
            topk = min(top_k, len(user_scores))
            top_indices = torch.topk(user_scores, k=topk).indices
            result[user_id] = [user_playlists[i] for i in top_indices]

    return result

## Example usage

test_user_ids = [42, 58, 90, 99999999]

# Call the batched inference function
ranked_results = rank_playlists_for_users(test_user_ids, top_k=5)

# Print results
print("\n--- Batched Inference Results ---")
for user_id in test_user_ids:
    playlists = ranked_results.get(user_id, [])
    if playlists:
        print(f"User {user_id} → Top-{len(playlists)} Playlists: {playlists}")
    else:
        print(f"User {user_id} → No candidate playlists available.")

print (ranked_results)

import pickle
from collections import Counter

# Get the mainstream user’s playlists
mainstream_user_id = 841706
mainstream_playlists = user_to_playlists.get(mainstream_user_id, [])

print(f"User {mainstream_user_id} has {len(mainstream_playlists)} matched playlists.")

# Build playlist popularity counter
playlist_counter = Counter()
for playlists in user_to_playlists.values():
    playlist_counter.update(playlists)

# Get popularity of this user’s playlists
playlist_popularities = [playlist_counter[p] for p in mainstream_playlists]

# Top 10 most popular playlists
top_playlists = sorted(
    [(p, playlist_counter[p]) for p in mainstream_playlists],
    key=lambda x: x[1],
    reverse=True
)[:10]

print("\nTop 10 Playlists:")
for pid, count in top_playlists:
    print(f"Playlist {pid}: matched by {count} users")

# Average popularity
avg_popularity = sum(playlist_popularities) / len(playlist_popularities)
print(f"\nAverage popularity of this user's playlists: {avg_popularity:.2f}")