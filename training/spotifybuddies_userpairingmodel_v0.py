# -*- coding: utf-8 -*-
"""SpotifyBuddies_UserPairingModel_v0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10K2zEIW1Q-6s-W3MNuV6A3TltvftGoRw

# User Pairing Model
"""

import pickle
import random
from tqdm import tqdm
from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix

# === Config ===
USER_MATRIX_PATH = "/content/drive/MyDrive/datasets/user_matrix.pkl"
USER_TO_IDX_PATH = "/content/drive/MyDrive/datasets/user_to_idx.pkl"
SELECTED_USERS_PATH = "/content/drive/MyDrive/datasets/userplaylist_labeled_slices_fixed_downscaled/selected_user_ids.pkl"
OWNED_PLAYLISTS_PATH = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"
OUTPUT_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled.pkl"

TOP_K = 100
MIN_PL = 20
MAX_PL = 100
SEED = 42
random.seed(SEED)

# === Load all data ===
print("Loading sparse matrix and mappings...")
with open(USER_MATRIX_PATH, "rb") as f:
    user_matrix: csr_matrix = pickle.load(f)

with open(USER_TO_IDX_PATH, "rb") as f:
    user_to_idx = pickle.load(f)

with open(SELECTED_USERS_PATH, "rb") as f:
    selected_user_ids = pickle.load(f)

with open(OWNED_PLAYLISTS_PATH, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Prepare index mappings
idx_to_user = {v: k for k, v in user_to_idx.items()}
selected_idx = sorted([idx for uid, idx in user_to_idx.items() if idx in selected_user_ids])
sub_matrix = user_matrix[selected_idx]

print(f"‚úÖ Using {len(selected_idx)} users for sub-matrix: shape = {sub_matrix.shape}")

# === Fit KNN model
print("Fitting sparse KNN model...")
knn = NearestNeighbors(n_neighbors=TOP_K + 1, algorithm="brute", metric="cosine", n_jobs=-1)
knn.fit(sub_matrix)

# === Neighbor selection
user_neighbors = {}
for i, user_row in enumerate(tqdm(sub_matrix, desc="Matching neighbors")):
    user_idx = selected_idx[i]
    distances, indices = knn.kneighbors(user_row, n_neighbors=TOP_K + 1)
    neighbor_indices = [selected_idx[nbr] for nbr in indices.flatten() if selected_idx[nbr] != user_idx]

    random.shuffle(neighbor_indices)  # Shuffle to avoid positional bias! Important issue that was fixed haha

    total_playlists = set()
    selected_neighbors = []

    for nbr_id in neighbor_indices:
        pl = user_owned_playlists.get(nbr_id, set())
        total_playlists.update(pl)
        selected_neighbors.append(nbr_id)
        if len(total_playlists) >= MIN_PL:
            if len(total_playlists) >= MAX_PL:
                break

    user_neighbors[user_idx] = selected_neighbors

# === Save results
with open(OUTPUT_PATH, "wb") as f:
    pickle.dump(user_neighbors, f)

print(f"‚úÖ Saved {len(user_neighbors)} users with neighbors ‚Üí {OUTPUT_PATH}")

"""## Explore KNN results!"""

import os
import numpy as np
import matplotlib.pyplot as plt
import random

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled.pkl"
SAMPLE_USERS = 5
SEED = 42
random.seed(SEED)

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

print(f"‚úÖ Loaded {len(user_neighbors):,} users with neighbor lists.")

# === Compute Stats ===
neighbor_counts = [len(v) for v in user_neighbors.values()]

print("\nüìä Neighbor Count Statistics:")
print(f" - Users analyzed       : {len(neighbor_counts):,}")
print(f" - Min neighbors        : {min(neighbor_counts)}")
print(f" - Max neighbors        : {max(neighbor_counts)}")
print(f" - Mean neighbors       : {np.mean(neighbor_counts):.2f}")
print(f" - Median neighbors     : {np.median(neighbor_counts)}")
print(f" - 25th percentile      : {np.percentile(neighbor_counts, 25)}")
print(f" - 75th percentile      : {np.percentile(neighbor_counts, 75)}")
print(f" - 99th percentile      : {np.percentile(neighbor_counts, 99)}")

# === Plot Histogram ===
plt.figure(figsize=(8, 5))
plt.hist(neighbor_counts, bins=30, color="steelblue", edgecolor="black")
plt.title("Distribution of Neighbor Count per User")
plt.xlabel("Number of Neighbors")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

# === Sample Users for Manual Check ===
print(f"\nüîç Sampling {SAMPLE_USERS} users and showing their neighbors:")
sample_keys = random.sample(list(user_neighbors.keys()), SAMPLE_USERS)
for uid in sample_keys:
    print(f"\nUser {uid} has {len(user_neighbors[uid])} neighbors ‚Üí {user_neighbors[uid]}")import pickle

import pickle
import random

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"
NUM_USERS_TO_SAMPLE = 5

# === Load Files ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Sample and Analyze ===
print(f"Sampling {NUM_USERS_TO_SAMPLE} users and checking playlist access:")
sample_users = random.sample(list(user_neighbors.keys()), NUM_USERS_TO_SAMPLE)

for uid in sample_users:
    neighbors = user_neighbors[uid]
    all_playlists = set()

    for nbr in neighbors:
        all_playlists.update(user_owned_playlists.get(nbr, set()))

    print(f"\nUser {uid}:")
    print(f" - Paired with {len(neighbors)} users")
    print(f" - Has access to {len(all_playlists)} unique playlists from neighbors")

import pickle
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled.pkl"

# === Load Neighbors ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

# === Invert Mapping to Count Popularity ===
neighbor_flat_list = [nbr for neighbors in user_neighbors.values() for nbr in neighbors]
popularity_counter = Counter(neighbor_flat_list)

popularity_counts = list(popularity_counter.values())

# === Stats ===
print("\nüìä User Popularity (Times a User Was Paired as Neighbor):")
print(f" - Users selected as neighbor: {len(popularity_counts):,}")
print(f" - Min times selected        : {min(popularity_counts)}")
print(f" - Max times selected        : {max(popularity_counts)}")
print(f" - Mean                      : {np.mean(popularity_counts):.2f}")
print(f" - Median                    : {np.median(popularity_counts)}")
print(f" - 90th percentile           : {np.percentile(popularity_counts, 90)}")
print(f" - 99th percentile           : {np.percentile(popularity_counts, 99)}")

# === Histogram ===
plt.figure(figsize=(8, 5))
plt.hist(popularity_counts, bins=30, color="orchid", edgecolor="black")
plt.title("Distribution of User Popularity (Times Selected as Neighbor)")
plt.xlabel("Times Selected as Neighbor")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.6)
plt.tight_layout()
plt.show()

import pickle
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Compute playlists accessible via neighbors ===
playlist_counts = []

for uid, neighbors in tqdm(user_neighbors.items(), desc="Computing playlist coverage"):
    playlists = set()
    for nbr in neighbors:
        playlists.update(user_owned_playlists.get(nbr, set()))
    playlist_counts.append(len(playlists))

# === Stats ===
print("\nüìä Playlists Accessible via Neighbors:")
print(f" - Users analyzed         : {len(playlist_counts):,}")
print(f" - Min playlists          : {min(playlist_counts)}")
print(f" - Max playlists          : {max(playlist_counts)}")
print(f" - Mean playlists         : {np.mean(playlist_counts):.2f}")
print(f" - Median playlists       : {np.median(playlist_counts)}")
print(f" - 25th percentile        : {np.percentile(playlist_counts, 25)}")
print(f" - 75th percentile        : {np.percentile(playlist_counts, 75)}")
print(f" - 99th percentile        : {np.percentile(playlist_counts, 99)}")

# === Plot histogram ===
plt.figure(figsize=(8, 5))
plt.hist(playlist_counts, bins=30, color="teal", edgecolor="black")
plt.title("Distribution of Playlist Access via Neighbors")
plt.xlabel("Playlists Accessible Through Neighbors")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

"""## Second run with some fixes to allow all users to get a neighbour, and also control the surge at 100 playlists."""

import os
import pickle
import random
from tqdm import tqdm
from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix

# === CONFIGURATION ===
USER_MATRIX_PATH = "/content/drive/MyDrive/datasets/user_matrix.pkl"
USER_TO_IDX_PATH = "/content/drive/MyDrive/datasets/user_to_idx.pkl"
SELECTED_USERS_PATH = "/content/drive/MyDrive/datasets/userplaylist_labeled_slices_fixed_downscaled/selected_user_ids.pkl"
OWNED_PLAYLISTS_PATH = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"
OUTPUT_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"


TEST_ON_1PERCENT_USERS = True

# PARAMETERS
TOP_K = 100           # Number of candidates retrieved from KNN
MAX_NEIGHBORS = 50    # Soft cap on neighbor count
MIN_PL = 20           # Hard minimum on total playlists gathered from neighbors
SEED = 42
random.seed(SEED)

# === Load Data ===
print("Loading required files...")
with open(USER_MATRIX_PATH, "rb") as f:
    user_matrix: csr_matrix = pickle.load(f)

with open(USER_TO_IDX_PATH, "rb") as f:
    user_to_idx = pickle.load(f)

with open(SELECTED_USERS_PATH, "rb") as f:
    selected_user_ids = pickle.load(f)

with open(OWNED_PLAYLISTS_PATH, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Prepare index mappings and submatrix
idx_to_user = {v: k for k, v in user_to_idx.items()}
selected_idx = sorted([idx for uid, idx in user_to_idx.items() if idx in selected_user_ids])
sub_matrix = user_matrix[selected_idx]

print(f"‚úÖ Sub-matrix created ‚Üí shape = {sub_matrix.shape}")

# === Fit KNN model (cosine distance)
print("Fitting NearestNeighbors model (cosine distance)...")
knn = NearestNeighbors(n_neighbors=TOP_K + 1, algorithm="brute", metric="cosine", n_jobs=-1)
knn.fit(sub_matrix)

# === Find neighbors
print("Matching users to neighbors...")
user_neighbors = {}
for i, user_row in enumerate(tqdm(sub_matrix, desc="Pairing users")):
    user_idx = selected_idx[i]
    distances, indices = knn.kneighbors(user_row, n_neighbors=TOP_K + 1)
    neighbor_indices = [selected_idx[nbr] for nbr in indices.flatten() if selected_idx[nbr] != user_idx]
    random.shuffle(neighbor_indices)  # Remove ordering bias, vry important

    total_playlists = set()
    selected_neighbors = []

    for nbr_id in neighbor_indices:
        pl = user_owned_playlists.get(nbr_id, set())
        if not pl:
            continue
        total_playlists.update(pl)
        selected_neighbors.append(nbr_id)

        if len(selected_neighbors) >= MAX_NEIGHBORS and len(total_playlists) >= MIN_PL:
            break

    user_neighbors[user_idx] = selected_neighbors

# === Save results
os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
with open(OUTPUT_PATH, "wb") as f:
    pickle.dump(user_neighbors, f)

print(f"‚úÖ Saved neighbor pairs for {len(user_neighbors)} users ‚Üí {OUTPUT_PATH}")

import os
import numpy as np
import matplotlib.pyplot as plt
import random

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"
SAMPLE_USERS = 5
SEED = 42
random.seed(SEED)

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

print(f"‚úÖ Loaded {len(user_neighbors):,} users with neighbor lists.")

# === Compute Stats ===
neighbor_counts = [len(v) for v in user_neighbors.values()]

print("\nüìä Neighbor Count Statistics:")
print(f" - Users analyzed       : {len(neighbor_counts):,}")
print(f" - Min neighbors        : {min(neighbor_counts)}")
print(f" - Max neighbors        : {max(neighbor_counts)}")
print(f" - Mean neighbors       : {np.mean(neighbor_counts):.2f}")
print(f" - Median neighbors     : {np.median(neighbor_counts)}")
print(f" - 25th percentile      : {np.percentile(neighbor_counts, 25)}")
print(f" - 75th percentile      : {np.percentile(neighbor_counts, 75)}")
print(f" - 99th percentile      : {np.percentile(neighbor_counts, 99)}")

# === Plot Histogram ===
plt.figure(figsize=(8, 5))
plt.hist(neighbor_counts, bins=30, color="steelblue", edgecolor="black")
plt.title("Distribution of Neighbor Count per User")
plt.xlabel("Number of Neighbors")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

# === Sample Users for Manual Check ===
print(f"\nüîç Sampling {SAMPLE_USERS} users and showing their neighbors:")
sample_keys = random.sample(list(user_neighbors.keys()), SAMPLE_USERS)
for uid in sample_keys:
    print(f"\nUser {uid} has {len(user_neighbors[uid])} neighbors ‚Üí {user_neighbors[uid]}")

import pickle
import random

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"
NUM_USERS_TO_SAMPLE = 5

# === Load Files ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Sample and Analyze ===
print(f"Sampling {NUM_USERS_TO_SAMPLE} users and checking playlist access:")
sample_users = random.sample(list(user_neighbors.keys()), NUM_USERS_TO_SAMPLE)

for uid in sample_users:
    neighbors = user_neighbors[uid]
    all_playlists = set()

    for nbr in neighbors:
        all_playlists.update(user_owned_playlists.get(nbr, set()))

    print(f"\nUser {uid}:")
    print(f" - Paired with {len(neighbors)} users")
    print(f" - Has access to {len(all_playlists)} unique playlists from neighbors")

import pickle
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"

# === Load Neighbors ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

# === Invert Mapping to Count Popularity ===
neighbor_flat_list = [nbr for neighbors in user_neighbors.values() for nbr in neighbors]
popularity_counter = Counter(neighbor_flat_list)

popularity_counts = list(popularity_counter.values())

# === Stats ===
print("\nüìä User Popularity (Times a User Was Paired as Neighbor):")
print(f" - Users selected as neighbor: {len(popularity_counts):,}")
print(f" - Min times selected        : {min(popularity_counts)}")
print(f" - Max times selected        : {max(popularity_counts)}")
print(f" - Mean                      : {np.mean(popularity_counts):.2f}")
print(f" - Median                    : {np.median(popularity_counts)}")
print(f" - 90th percentile           : {np.percentile(popularity_counts, 90)}")
print(f" - 99th percentile           : {np.percentile(popularity_counts, 99)}")

# === Histogram ===
plt.figure(figsize=(8, 5))
plt.hist(popularity_counts, bins=30, color="orchid", edgecolor="black")
plt.title("Distribution of User Popularity (Times Selected as Neighbor)")
plt.xlabel("Times Selected as Neighbor")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.6)
plt.tight_layout()
plt.show()

import pickle
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Compute playlists accessible via neighbors ===
playlist_counts = []

for uid, neighbors in tqdm(user_neighbors.items(), desc="Computing playlist coverage"):
    playlists = set()
    for nbr in neighbors:
        playlists.update(user_owned_playlists.get(nbr, set()))
    playlist_counts.append(len(playlists))

# === Stats ===
print("\nüìä Playlists Accessible via Neighbors:")
print(f" - Users analyzed         : {len(playlist_counts):,}")
print(f" - Min playlists          : {min(playlist_counts)}")
print(f" - Max playlists          : {max(playlist_counts)}")
print(f" - Mean playlists         : {np.mean(playlist_counts):.2f}")
print(f" - Median playlists       : {np.median(playlist_counts)}")
print(f" - 25th percentile        : {np.percentile(playlist_counts, 25)}")
print(f" - 75th percentile        : {np.percentile(playlist_counts, 75)}")
print(f" - 99th percentile        : {np.percentile(playlist_counts, 99)}")

# === Plot histogram ===
plt.figure(figsize=(8, 5))
plt.hist(playlist_counts, bins=30, color="teal", edgecolor="black")
plt.title("Distribution of Playlist Access via Neighbors")
plt.xlabel("Playlists Accessible Through Neighbors")
plt.ylabel("Number of Users")
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

import pickle
import numpy as np
from tqdm import tqdm

# === Config ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Count playlists for each user
playlist_counts = []

for uid, neighbors in tqdm(user_neighbors.items(), desc="Counting playlists per user"):
    playlists = set()
    for nbr in neighbors:
        playlists.update(user_owned_playlists.get(nbr, set()))
    playlist_counts.append(len(playlists))

playlist_counts = np.array(playlist_counts)
total_users = len(playlist_counts)

# === Threshold stats
thresholds = [1, 5, 10, 20, 30, 50]
print("üìä Users with fewer than X playlists:")
for t in thresholds:
    count = np.sum(playlist_counts < t)
    share = (count / total_users) * 100
    print(f" - < {t:>2} playlists: {count:>6,} users ({share:5.2f}%)")

print(f"\n‚úÖ Total users analyzed: {total_users:,}")

"""## Save precomputed user to neighbor's playlist pairing, setting a max of 75 playlists."""

import os
import pickle
import random
from tqdm import tqdm

# === Configuration ===
NEIGHBOR_FILE = "/content/drive/MyDrive/datasets/main_datasets/user_pairing_model/user_neighbors_downscaled_v2.pkl"
OWNED_PLAYLISTS_FILE = "/content/drive/MyDrive/datasets/playlist_ownership/user_owned_playlists.pkl"
OUTPUT_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_playlist_match/user_to_neighboursPlaylists.pkl"
MAX_PLAYLISTS = 75
SEED = 42
random.seed(SEED)

# === Load Data ===
with open(NEIGHBOR_FILE, "rb") as f:
    user_neighbors = pickle.load(f)

with open(OWNED_PLAYLISTS_FILE, "rb") as f:
    user_owned_playlists = pickle.load(f)

# === Build Mapping: user_id ‚Üí list of playlist_ids
user_to_playlists = {}

for user_id, neighbors in tqdm(user_neighbors.items(), desc="Building mapping"):
    playlists = set()
    for nbr in neighbors:
        playlists.update(user_owned_playlists.get(nbr, set()))

    playlist_list = list(playlists)
    if len(playlist_list) > MAX_PLAYLISTS:
        playlist_list = random.sample(playlist_list, MAX_PLAYLISTS)
    user_to_playlists[user_id] = playlist_list

# === Save for Inference ===
os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
with open(OUTPUT_PATH, "wb") as f:
    pickle.dump(user_to_playlists, f)

print(f"‚úÖ Saved user-to-playlist mapping with {len(user_to_playlists)} users ‚Üí {OUTPUT_PATH}")

import os
import pickle

# === Configuration ===
INPUT_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_playlist_match/user_to_neighboursPlaylists.pkl"
OUTPUT_CLEAN_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_playlist_match/user_to_neighboursPlaylists_clean.pkl"
REMOVED_USERS_PATH = "/content/drive/MyDrive/datasets/main_datasets/user_playlist_match/removed_users_5playlistsRequirement.pkl"
MIN_PLAYLISTS = 5

# === Load original user‚Üíplaylist mapping
with open(INPUT_PATH, "rb") as f:
    user_to_playlists = pickle.load(f)

# === Filter users
user_to_playlists_clean = {}
removed_users = set()

for user_id, playlist_ids in user_to_playlists.items():
    if len(playlist_ids) >= MIN_PLAYLISTS:
        user_to_playlists_clean[user_id] = playlist_ids
    else:
        removed_users.add(user_id)

# === Save outputs
with open(OUTPUT_CLEAN_PATH, "wb") as f:
    pickle.dump(user_to_playlists_clean, f)

with open(REMOVED_USERS_PATH, "wb") as f:
    pickle.dump(removed_users, f)

print(f"‚úÖ Cleaned mapping saved: {len(user_to_playlists_clean)} users kept.")
print(f"üóëÔ∏è Removed {len(removed_users)} users with < {MIN_PLAYLISTS} playlists.")